<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Alternative Input Signals Ease Transfer in Multilingual Machine Translation</title>
      <link href="/2022/09/19/Alternative_Input_Signals_Ease_Transfer_in_Multilingual_Machine_Translation/"/>
      <url>/2022/09/19/Alternative_Input_Signals_Ease_Transfer_in_Multilingual_Machine_Translation/</url>
      
        <content type="html"><![CDATA[<h1 id="Alternative-Input-Signals-Ease-Transfer-in-Multilingual-Machine-Translation"><a href="#Alternative-Input-Signals-Ease-Transfer-in-Multilingual-Machine-Translation" class="headerlink" title="Alternative Input Signals Ease Transfer in Multilingual Machine Translation"></a>Alternative Input Signals Ease Transfer in Multilingual Machine Translation</h1><h2 id="前情提要"><a href="#前情提要" class="headerlink" title="前情提要"></a>前情提要</h2><p>MMT对低资源语言来说很有用，因为在模型可以利用不同语言的相似性和不同语言之间的共享信息来提高低资源语言的翻译效果。对于不同语言的共享信息这一点来说，最基本的就是两个语言之间的重叠tokens,这些tokens通常含有相同的含义，低资源语言的翻译能借鉴模型中存储的高资源语言的信息。如果语言间的重叠很少：例如只有标点符号和数字，那么就没办法有效利用这部分信息。此外，如果两种语言处于不同书写的字体系统时，重叠也会很少。</p><h2 id="语言共享信息方法"><a href="#语言共享信息方法" class="headerlink" title="语言共享信息方法"></a>语言共享信息方法</h2><p>为了解决由于不同书写系统（<code>scripts</code>、<code>writting systems</code>）引起的不同语言之间的重叠太少问题，作者提出了以下三种信号转化方法（<code>transliteration</code>、<code>signal system</code>）</p><h3 id="国际音标法"><a href="#国际音标法" class="headerlink" title="国际音标法"></a>国际音标法</h3><p>很多语言中的许多词发音是相同的，但是在不同的书写系统来看他们是完全不重叠的。因此为了运用这部分重叠的信息，将文本通过国际音标转为音标文本，其中音标的单位是音素。当然这种方法也会引入噪声，例如：</p><ol><li>标点符号可能在转化过程中丢失（或许可以标记增加断句信息？）</li><li>对于一种语言来说不同词可能会发相同的音，但是是完全的不同字形。</li><li>一个字可能还有不同发音，不同发音的意思不同（<strong>个人想法</strong>）</li></ol><h3 id="罗马化法"><a href="#罗马化法" class="headerlink" title="罗马化法"></a>罗马化法</h3><p>在现代化过程中，很多语言都能通过键盘上的26个字母输入到电脑中，因此语言或多或少具有这种罗马形式（例如汉字拼音）。</p><h3 id="转化为其他语言字体法"><a href="#转化为其他语言字体法" class="headerlink" title="转化为其他语言字体法"></a>转化为其他语言字体法</h3><p>之前两种方式会增加模型需要学习的语言表示量，并且词汇表也要相应扩充。这种方法是将一种语言转化为同源语言族中一种语言，这样也不需要提前学习subword等。</p><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><p>利用这三种方法不需要额外的模型，例如第一种方法可以直接使用音标对齐直接转化（可以利用工具包<code>espkea-ng</code>），第二种方法可以使用工具包<code>indic-trans</code>，第三种可以用字母表对齐实现(手动实现)。</p><h2 id="多种转化后的信号融合"><a href="#多种转化后的信号融合" class="headerlink" title="多种转化后的信号融合"></a>多种转化后的信号融合</h2><h3 id="Straight-Concatenation"><a href="#Straight-Concatenation" class="headerlink" title="Straight Concatenation"></a>Straight Concatenation</h3><p>简单，不需要改变模型架构，使用特殊的tokens分隔不同输入，代价是句子长的话就需要更多的计算。</p><h3 id="Multi-Encoder-Architectures"><a href="#Multi-Encoder-Architectures" class="headerlink" title="Multi-Encoder Architectures"></a>Multi-Encoder Architectures</h3><p>为每个信号准备一个Encoder，也就是多个Encoder,一个decoder模型，多个encoder组合方式不同，主要有4种（<a href="https://arxiv.org/abs/1811.04716v1">Libovick ́ y et al. (2018)</a>），对应的encoder-decoder attention（cross attention）也有不同形式。<strong>虽然之前证明有效，但是还是需要更巧妙的模型设计才能达到更好的性能</strong></p><h3 id="Multi-Source-Ensemble"><a href="#Multi-Source-Ensemble" class="headerlink" title="Multi-Source Ensemble"></a>Multi-Source Ensemble</h3><p>多个模型，不同模型除了输入信号不同其他都相同，最后将每个模型输出的概率分布平均。缺点：超多计算。</p><h3 id="Multi-Source-Self-Ensemble"><a href="#Multi-Source-Self-Ensemble" class="headerlink" title="Multi-Source Self-Ensemble"></a>Multi-Source Self-Ensemble</h3><p>借鉴了集成多种信号的优点，但是只需要训练一个模型。对于一个句子来说，转为不同信号，每个信号前面加上特定的token，重复经过模型得到概率分布，最后将概率分布平均。<br><a href="/img/Alternative_Input_Signals_Ease_Transfer_in_Multilingual_Machine_Translation/1.jpg">模型结构图</a></p><h2 id="实验分析"><a href="#实验分析" class="headerlink" title="实验分析"></a>实验分析</h2><p>翻译方向为<code>XX-&gt;EN</code>，语言族：<code>Indic,Turkic</code><br><a href="/img/Alternative_Input_Signals_Ease_Transfer_in_Multilingual_Machine_Translation/2.jpg">模型结构图</a><br>对于<strong>多源自集成</strong>来说：</p><ol><li>单独的转化后的信号不会使得BLEU提升，甚至有些下降。原因是引入的干扰大于有效信息。</li><li>单独的转化后的信号和原始信号一起输入会使得BLEU提升，但是最多在1.0左右</li><li>将encoder参数量提升一倍，BLEU的值提升1.3。</li></ol><h3 id="多源自集成优势"><a href="#多源自集成优势" class="headerlink" title="多源自集成优势"></a>多源自集成优势</h3><ol><li>seq2seq模型架构不需要做改变</li><li>在低资源语料的情况下，比基线水平的BLEU提升更大达到5.0。并且随着数据集大小增大始终优于基线水平。</li><li>生成的假设较为一致，作者提出的C-BLEU更好（We treat the output of L1-En direction as reference and out-put of all other Li-En directions as hypothesis. We compute this for all N source languages in the dataset, accounting for total N (N − 1) C-BLEU scores, then take the average of all）</li><li>生成的句子使用NER去抽取实体，不同类别的实体识别的效果都优于基线。表明生成句子更准确。</li></ol><p><img src="/img/Alternative_Input_Signals_Ease_Transfer_in_Multilingual_Machine_Translation/3.jpg" alt="第二点"><br><img src="/img/Alternative_Input_Signals_Ease_Transfer_in_Multilingual_Machine_Translation/4.jpg" alt="第三点"></p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>作者为了解决不同语言之间信息重叠过少的问题，提出了三种不同的信号转化方式和多源自集成方法使得翻译性能提升，准确性也有提升。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 机器翻译 </tag>
            
            <tag> 多语言机器翻译 </tag>
            
            <tag> 自然语言处理 </tag>
            
            <tag> 论文阅读 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pre-Trained Multilingual Sequence-to-Sequence Models: A Hope for Low-Resource Language Translation?</title>
      <link href="/2022/09/19/Pre-Trained_Multilingual_Sequence-to-Sequence_Models_A_Hope_for_Low-Resource_Language_Translation/"/>
      <url>/2022/09/19/Pre-Trained_Multilingual_Sequence-to-Sequence_Models_A_Hope_for_Low-Resource_Language_Translation/</url>
      
        <content type="html"><![CDATA[<h1 id="Pre-Trained-Multilingual-Sequence-to-Sequence-Models-A-Hope-for-Low-Resource-Language-Translation"><a href="#Pre-Trained-Multilingual-Sequence-to-Sequence-Models-A-Hope-for-Low-Resource-Language-Translation" class="headerlink" title="Pre-Trained Multilingual Sequence-to-Sequence Models: A Hope for Low-Resource Language Translation?"></a>Pre-Trained Multilingual Sequence-to-Sequence Models: A Hope for Low-Resource Language Translation?</h1><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>该篇论文主要以mBART(一种预训练端到端多语言模型)为模型架构探索数据集对性能的影响，也形成了一种衡量模型的数据敏感性的框架，经过实验，文章提出的一个结论是<strong>与其想着怎么微调模型，还不如从数据上改进以更大提升表现，增强实用性。</strong></p><p>PMSS(预训练端到端多语言模型)<strong>数据集敏感性</strong>可探究的几个方面：</p><ul><li>微调训练时所需的数据量</li><li>微调数据集中的噪声</li><li>预训练数据集数量</li><li>领域不匹配问题</li><li>语言类型问题</li></ul><h3 id="mBART模型介绍"><a href="#mBART模型介绍" class="headerlink" title="mBART模型介绍"></a>mBART模型介绍</h3><p>首先这是一个纯用Transformer架构的预训练模型，预训练数据是Common Crawl,具有多种语言的文本数据。mBART的预训练目标是单语形式的，将原句子一定程度上破坏之后使用模型重建这个句子。这种目标函数比较有意思，它不引导模型产生相似的tokens或者representations。（<strong>疑问点，待续</strong>）在经过预训练后可以有监督或者直接进行翻译训练、预测。</p><h2 id="实验部分"><a href="#实验部分" class="headerlink" title="实验部分"></a>实验部分</h2><h3 id="评测语言选择"><a href="#评测语言选择" class="headerlink" title="评测语言选择"></a>评测语言选择</h3><p>文章选了10种语言，8种低资源语言和2种高资源语言（FR,HI）。在字体方面也有分类，主要为Latin和非Latin。在未知语言上也有分类，有4种语言是mBART在预训练未接触过的。具体统计如下图：<br><img src="/img/Pre-Trained_Multilingual_Sequence-to-Sequence_Models_A_Hope_for_Low-Resource_Language_Translation/2.jpg" alt="评测语言的具体信息,Joshi class用来划分资源高低，大于3算高资源语言"></p><h3 id="平行语料"><a href="#平行语料" class="headerlink" title="平行语料"></a>平行语料</h3><p>语料选择上既有Common Crawl（数量大、开放域、使用自动对齐上可能有噪声）、Bible等。包括开放域和领域特定的语料、并且将训练数据按照数量大小进行切割以进行下一步实验。<br><img src="/img/Pre-Trained_Multilingual_Sequence-to-Sequence_Models_A_Hope_for_Low-Resource_Language_Translation/3.jpg" alt="语料具体信息"></p><h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><p>实验以EN-&gt;XX和XX-&gt;EN为翻译方向。每个语言有3个测试集（2个特定域，FLORES是开放域），分别使用不同数量、不同类型的数据集进行微调训练得到结果。</p><p><img src="/img/Pre-Trained_Multilingual_Sequence-to-Sequence_Models_A_Hope_for_Low-Resource_Language_Translation/4.jpg" alt="实验结果1"></p><p><img src="/img/Pre-Trained_Multilingual_Sequence-to-Sequence_Models_A_Hope_for_Low-Resource_Language_Translation/5.jpg" alt="实验结果2"></p><h3 id="实验分析"><a href="#实验分析" class="headerlink" title="实验分析"></a>实验分析</h3><h4 id="微调训练时所需的数据量"><a href="#微调训练时所需的数据量" class="headerlink" title="微调训练时所需的数据量"></a>微调训练时所需的数据量</h4><ol><li>使用Common Crawl（开放域）,mBART模型使用25k的数据在性能上远超用100k数据的transformer模型，这在大多数语言上都得到验证，也有一两个低资源语言两者的表现都很不好。（test时候语言是预训练时就接触到的模型）</li><li>使用特定域的数据进行微调，结果也是mBART优于transformer。</li><li>微调训练的句子对数将在<code>50k</code>左右达到一个饱和，数量加大的话会导致预训练的参数改变过多，预训练保留的信息被冲掉，（mBART是标准Transformer架构，参数量约<code>680M</code>，预训练语料远大于50k）</li></ol><h4 id="微调数据集中的噪声"><a href="#微调数据集中的噪声" class="headerlink" title="微调数据集中的噪声"></a>微调数据集中的噪声</h4><p>这里噪声指的是是否和领域相关的数据。根据实验结果表明，mBART微调时相同领域的训练数据只需要开放域训练数据量的十分之一就能达到更好的效果。</p><h4 id="预训练数据集数量"><a href="#预训练数据集数量" class="headerlink" title="预训练数据集数量"></a>预训练数据集数量</h4><p><strong>mBART模型比transfomer进步的地方在于性能提升上，高资源语言更显著</strong>，个人认为句法结构和词语的多样性对于数据集来说很重要，因为模型的可拓展能力可能不够，没办法像人一样举一反三。那对应语料的数据量越大涵盖的词语和句子更多变，使得模型能够更好的将语言特征通过预训练保存到参数中，反过来说mBART确实能够很好利用预训练学习到，因为观察出了不同语言的差异。<br><img src="/img/Pre-Trained_Multilingual_Sequence-to-Sequence_Models_A_Hope_for_Low-Resource_Language_Translation/6.jpg" alt="预训练语料中语言的数量和实验的BLEU值关系"></p><h4 id="领域不匹配问题"><a href="#领域不匹配问题" class="headerlink" title="领域不匹配问题"></a>领域不匹配问题</h4><ol><li>领域相同的训练集和测试集效果要比不匹配的情况好。</li><li>开放域训练的模型可能在特定领域的测试集上表现得比开放域数据集好。</li><li>预训练数据越大越能在特定域数据集上表现出色，可以弥补特定域数据集不足的问题。</li></ol><h4 id="语言类型问题"><a href="#语言类型问题" class="headerlink" title="语言类型问题"></a>语言类型问题</h4><ol><li>如果一个低资源语言和目标语言有较多的token片段重叠或者相似的句法特征（主谓宾顺序、辅音突变等语法现象），那么在翻译的时候就可以得到更好的结果。</li><li><strong>翻译成英语总比英语翻译成其他语言的BLEU要好</strong>。这可以说是decoder更好地学到了英语这个语言，也有可能是由于BLEU不将子词纳入计算范围，这导致有些词素是对的但是整个词错了，从而导致翻译成其他语言的BLEU值不高。</li></ol><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ol><li>对于开放域的翻译来说，mBART比原始transformers架构只需要更少的微调数据就能达到更好的效果（<code>4-10倍</code>）</li><li>对于特定域的翻译来说，mBART数据量有效性为<code>5-10倍</code>,并且同时也更鲁棒，在领域外表现更好。</li><li>对于预训练数据集中没有出现的语言来说，BLEU表现非常差劲基本用不了。</li></ol><p>对于标题给出的疑问，PMSS能不能改善低语言资源，作者的回答是<strong>与其想着怎么微调模型，还不如想想怎么为低资源数据收集更多更好的训练句子</strong>（寄，不知道后面有无后续PMSS的文章）</p>]]></content>
      
      
      
        <tags>
            
            <tag> 机器翻译 </tag>
            
            <tag> 多语言机器翻译 </tag>
            
            <tag> 自然语言处理 </tag>
            
            <tag> 论文阅读 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Breaking Down Multilingual Machine Translation</title>
      <link href="/2022/09/19/Breaking_Down_Multilingual_Machine_Translation/"/>
      <url>/2022/09/19/Breaking_Down_Multilingual_Machine_Translation/</url>
      
        <content type="html"><![CDATA[<h1 id="Breaking-Down-Multilingual-Machine-Translation"><a href="#Breaking-Down-Multilingual-Machine-Translation" class="headerlink" title="Breaking Down Multilingual Machine Translation"></a>Breaking Down Multilingual Machine Translation</h1><h2 id="前情摘要"><a href="#前情摘要" class="headerlink" title="前情摘要"></a>前情摘要</h2><p>（之前文章提到过，多对一的翻译方向设置比一对多的翻译对双语翻译的性能提高更高。）<br>此外之前还有很多分析多语言翻译的文章如（<a href="https://arxiv.org/abs/1909.02197">Kudugunta et al., 2019</a>,<a href="https://arxiv.org/abs/1905.09418v1">Voita et al., 2019a</a>,<a href="https://aclanthology.org/2020.acl-main.688/">Aji et al., 2020</a>,<a href="https://aclanthology.org/2020.lrec-1.458">Mueller et al., 2020</a>）对多语言翻译模型进行了一些分析，但是这些分析并没有去探究<strong>不同翻译方向（如</strong><code>many-to-one</code><strong>）对模型中不同组成的影响，也没有检查模型中不同组成（</strong><code>encoder/decoder</code><strong>）各自的影响</strong>。这就是这篇文章主要探索的两部分。</p><h2 id="实验设置"><a href="#实验设置" class="headerlink" title="实验设置"></a>实验设置</h2><p>数据集：TED Talks Dataset。将全部文本进行BPE分词，包括全部语言，词汇表<code>32000</code>。模型架构是Transformer。</p><h2 id="多语言训练如何影响模型中各个部分"><a href="#多语言训练如何影响模型中各个部分" class="headerlink" title="多语言训练如何影响模型中各个部分"></a>多语言训练如何影响模型中各个部分</h2><p><strong>之前的实验表明，多语训练的模型比双语模型性能来的更好</strong>，为了探究到底是对encoder端还是decoder端有效，作者进行了实验。<br><img src="/img/Breaking_Down_Multilingual_Machine_Translation/1.jpg" alt="实验结果1"><br><img src="/img/Breaking_Down_Multilingual_Machine_Translation/2.jpg" alt="实验结果2"></p><p>其中<code>Bilingual Only</code>是只使用双语语料并且从零开始训练的模型。<code>Load xxx</code>表示从训练好的多语言模型加载对应部分参数，并且这部分参数是可以训练的。<code>Freeze xxx</code>同样是加载对应参数但是冻结的，不可更新的。之所以提出freeze是因为可能模型其他部分的随机初始化会使得这部分的效果得到削弱。从左到右前4个是低资源语言，后4个是高资源语言。</p><h3 id="实验结果分析"><a href="#实验结果分析" class="headerlink" title="实验结果分析"></a>实验结果分析</h3><p><strong>对低资源语言来说:</strong></p><ol><li>多语言训练通常对encoders和decoders都是有益的。<code>load Enc.</code>和<code>freeze Dec.</code>再次证实encoders和decoders确实会保留多语言训练中的有效信息，比只用双语语料训练来的有效。</li><li>多语言训练对encoders来说更有效，load encoder和freeze encoder的表现优于load decoder和load decoder。’</li></ol><p><strong>对高资源语言来说:</strong></p><ol><li>多语言训练通常对encoders是有益的，但在部分情况下对decoders不是有益的，<code>load Enc.</code>性能提升明显，但是在<code>load Enc.</code>和<code>freeze Dec.</code>表现不比基线好。</li><li>多语言训练对encoder来的更重要，<code>load Enc.</code>能得到更好的结果。</li></ol><p><strong>对两种类型语言来说</strong></p><ol><li>load both普遍要比只load其中一种好。</li><li>对于<code>en-&gt;xx</code>方向，load encoders会优于freeze encoders。对于<code>xx-&gt;en</code>方向，freeze decoders要优于load decoders（只有ALL-En中it-&gt;en不是，在低资源语言翻译上更明显）。前者证明了其实encoder端是和target language有关的。（因为load的话参数是会改变的，更有效地根据具体的语言将target language的信息加入到encoder中）,后者<strong>有待思考</strong></li></ol><h2 id="模型参数是如何共享于不同语言对"><a href="#模型参数是如何共享于不同语言对" class="headerlink" title="模型参数是如何共享于不同语言对"></a>模型参数是如何共享于不同语言对</h2><p><strong>Head importance estimation</strong>（<a href="https://arxiv.org/abs/1905.10650v1">Michel et al. (2019)</a>）<br>该方法主要利用的是损失对应于每个头的梯度来衡量每个头的重要性。在每个attention中对各个头的梯度进行标准化后得到每个头的重要性得分，具体定义如下图：<br><img src="/img/Breaking_Down_Multilingual_Machine_Translation/3.jpg" alt="Head importance estimation定义"><br><img src="/img/Breaking_Down_Multilingual_Machine_Translation/4.jpg" alt="Head importance estimation定义"></p><p><strong>对于一个Head来说，如果在两个语言对上的得分都很高的话，那么这个Head就是重要的并且是共享的。</strong></p><h3 id="结果分析"><a href="#结果分析" class="headerlink" title="结果分析"></a>结果分析</h3><p>实验方法：一组语言对的所有训练句子可以得到相应的<strong>一组</strong>Head-importance得分，将其转为等级排序，对不同语言对来说就可以利用这<strong>两组</strong>数据计算斯皮尔曼等级相关系数。那么这个相关系数有什么用呢，怎么用来衡量模型中不同组成部分的共享情况呢？ 答案就是：<strong>相关系数越高——&gt;一致性越高——&gt;参数共享程度越大</strong>。举例子说人话：<strong>比如有一部分参数P，语言对a在这上面的梯度（或importance score或者importance rank）和语言对b高度相似并且都很大的话，那么可以推测两个语言对在参数P上对结果（loss）的影响是高度相似的，反过来说也就是是参数P在不同语言对中是共享的。</strong>据此作者比较了encoder和decoder端的参数共享程度。<br><img src="/img/Breaking_Down_Multilingual_Machine_Translation/5.jpg" alt="实验结果"></p><p>根据这个结果可以分析不同语言对之间的信息是如何在不同部分共享/存在的。</p><h4 id="Encoder-for-En-X"><a href="#Encoder-for-En-X" class="headerlink" title="Encoder for En-X"></a>Encoder for En-X</h4><p>对于encoders端来说，EN-X的语言对得到的相关系数（0.806和0.813）都要小于X-EN得到的相关系数（0.871和0.898）。这可能表明encoder端的部分参数是用来编码生成和目标语言有关的中间表示。</p><h4 id="Encoder-for-X-En"><a href="#Encoder-for-X-En" class="headerlink" title="Encoder for X-En"></a>Encoder for X-En</h4><p>X-EN得到的相关系数（0.871和0.898）都很高，说明encoder端是有可能高度参数共享的。</p><h4 id="Decoder-for-En-X"><a href="#Decoder-for-En-X" class="headerlink" title="Decoder for En-X"></a>Decoder for En-X</h4><p>虽然系数很低，但是在部分语言对中是共享的。对于一个模型来说尽可能是要在多语言中都有效。</p><h4 id="Decoder-for-X-En"><a href="#Decoder-for-X-En" class="headerlink" title="Decoder for X-En"></a>Decoder for X-En</h4><p>系数都很高，这表明decoder端参数是高度共享的。虽然之前文章有人证明encoder生成的中间表示是目标语言无关的，但是decoder端的重要参数取决于目标语言（也即需要这部分参数去学习目标语言之间不同之处），这就解释了多语言训练为什么不有利于<code>XX-EN</code>中decoder。其中的一个启发点就是如果要使得<code>XX-EN</code>翻译更好的话，多语言训练应该暴露更多的<code>XX-EN</code>语料，其中英文句子要更多样。</p><h2 id="依据参数共享改进"><a href="#依据参数共享改进" class="headerlink" title="依据参数共享改进"></a>依据参数共享改进</h2><p>对于多语言训练来说选择什么样的语言去训练会导致最后的双语翻译结果不一样，直觉上我们认为如果用相近的语言去预训练，最后得到的结果会更好。但有时候不是这样，用完全不相关的语言去训练可以达到更好的效果。因此怎么选择训练的语言成为一个重要问题，作者提出一种衡量标准，也就是要选择<strong>能够使得参数更好共享的语言</strong>。</p><h3 id="Improving-X-En-by-Related-En-X-Pairs"><a href="#Improving-X-En-by-Related-En-X-Pairs" class="headerlink" title="Improving X-En by Related En-X Pairs"></a>Improving X-En by Related En-X Pairs</h3><p>改进的思路，之前的实验说明对语言训练可能对decoder端的增益没有比encoder端大，这可能说明decoder端的参数共享程度比较低。所以我们可以通过选择使得decoder端的共享程度高的语言集合，具体计算如下：<br><img src="/img/Breaking_Down_Multilingual_Machine_Translation/6.jpg" alt="语言集合选择计算"></p><p><img src="/img/Breaking_Down_Multilingual_Machine_Translation/7.jpg" alt="具体结果"><br>可以看到使用ALL-En语料微调的效果最好，其次是使用ALL-En语料+EN-ALL语料（其中ALL是计算得到的<strong>相关语言</strong>）。这也说明<strong>ALL-EN和EN-ALL训练语料如何使用会是一个难题，有待进一步探究和运用</strong>。</p><h3 id="Improving-En-X-by-Language-Clusters"><a href="#Improving-En-X-by-Language-Clusters" class="headerlink" title="Improving En-X by Language Clusters"></a>Improving En-X by Language Clusters</h3><p>和上一种方法思路类似，要用相关的语言对改进EN-X的表现，逻辑：<strong>使用相关语言对——&gt;能够使得参数共享越容易——&gt;参数共享程度越高——&gt;性能表现更好</strong>。<br>为了分析方便，作者使用t-SNE对一组head-importance scores进行降维，作者只关注decoders端的得分，因为decoders端的EN-ALL语料上的相关系数很低。降维完后，如果两种语言接近的话，那么作者认为其是相关的。<br><img src="/img/Breaking_Down_Multilingual_Machine_Translation/8.jpg" alt="t-SNE处理后得到语言分布"></p><p><img src="/img/Breaking_Down_Multilingual_Machine_Translation/9.jpg" alt="实验结果"><br>得到相近的语言族后作者进行了实验，得到以下结论</p><ol><li>对于EN-ALL、ALL-ALL模型来说，在相近语言族上微调能够提升性能。</li><li>对于低资源语言来说总体在相近语言族上微调要优于在随机语言组上微调。</li><li>虽然图表中看起来使用相近的语言族并没有提升很多，这可能是因为相关系数阈值不够大，如果阈值选为0.8得到最后一行的结果，在两种方向语言翻译上得到较大提升。</li></ol><p>为了验证这种使用语言族的方法会不会真的使得decoders端参数共享程度增加，作者进行了实验。<br><img src="/img/Breaking_Down_Multilingual_Machine_Translation/10.jpg" alt="使用语言族微调后的decoders端参数共享情况"></p>]]></content>
      
      
      
        <tags>
            
            <tag> 机器翻译 </tag>
            
            <tag> 多语言机器翻译 </tag>
            
            <tag> 自然语言处理 </tag>
            
            <tag> 论文阅读 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>wandb在fairseq的使用</title>
      <link href="/2022/09/04/wandb/"/>
      <url>/2022/09/04/wandb/</url>
      
        <content type="html"><![CDATA[<h2 id="注册wandb账号"><a href="#注册wandb账号" class="headerlink" title="注册wandb账号"></a>注册wandb账号</h2><p>首先到<a href="https://wandb.ai/site">wandb官网</a>注册一个账号，可以用github账号注册。<br><img src="/img/wandb/1.jpg" alt="个人账户页面">,可以提前创建个project，或者之后使用fairseq命令行创建新project。</p><h2 id="在命令行中创建wandb项目"><a href="#在命令行中创建wandb项目" class="headerlink" title="在命令行中创建wandb项目"></a>在命令行中创建wandb项目</h2><p>在之前创建账号时会自动产生一个API key，需要记住这个API key，如果没找到也可以在个人设置中找到。<br><img src="/img/wandb/3.jpg" alt="API key"><br>和之前一篇fairseq文章相同，在训练时多增加一个命令行参数<code>--wandb-project t</code>，其中t是wandb project名，如果不存在自动新建。<br>第一次启动wandb会要求输入API key,将其复制输入即可。<br><img src="/img/wandb/2.jpg" alt="输入API key"><br>打开wandb的个人project即可看到相应的图表记录。<br><img src="/img/wandb/4.jpg" alt="主要几种图表"><br><img src="/img/wandb/5.jpg" alt="valid数据"><br><strong>具体每个图表信息或者添加还需要进一步了解</strong></p><h2 id="图表对比"><a href="#图表对比" class="headerlink" title="图表对比"></a>图表对比</h2><p>主要目的：以train/loss为例对比不同参数或者模型下的loss曲线变化。<br><img src="/img/wandb/6.jpg" alt="两个正在运行的project，一个已经运行的project"><br>随便打开一个project的train/loss图表，点击右上角的三个点，选择<code>Add to report</code>。<br><img src="/img/wandb/7.jpg" alt="添加report"><br><img src="/img/wandb/8.jpg" alt="设置下名字"><br><strong>在这个report中就可以添加想要对比的曲线，曲线可以是正在运行的模型，也可以是已经运行完的模型</strong><br><img src="/img/wandb/9.jpg" alt="加号可以添加project，在project中进行切换，可以设置颜色和可见情况"><br><img src="/img/wandb/11.jpg" alt="之后点击保存即可看到对比图"></p>]]></content>
      
      
      
        <tags>
            
            <tag> fairseq </tag>
            
            <tag> 小助手 </tag>
            
            <tag> wandb </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>vscode+win10远程调试linux服务器python项目</title>
      <link href="/2022/09/02/vscode_remote_dubug/"/>
      <url>/2022/09/02/vscode_remote_dubug/</url>
      
        <content type="html"><![CDATA[<h2 id="vscode远程连接linux服务器"><a href="#vscode远程连接linux服务器" class="headerlink" title="vscode远程连接linux服务器"></a>vscode远程连接linux服务器</h2><p>这部分较为简单，大部分网上都有教程，<a href="https://mp.weixin.qq.com/s/s5IhxV2ooX3JN_X416nidA">推荐看这个</a>。连接上后vscode左下角有SSH连接标志。<br><img src="/img/vscode_remote_debug_md/1.jpg" alt="左下角截图"></p><p>接下来就可以打开相应的python项目了。<br><img src="/img/vscode_remote_debug_md/2.jpg" alt="打开fairseq项目文件夹"></p><h2 id="命令行参数设置"><a href="#命令行参数设置" class="headerlink" title="命令行参数设置"></a>命令行参数设置</h2><p>以fair-generate为例，命令行如下：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">fairseq-generate data-bin/iwslt14.tokenized.de-en \</span><br><span class="line">    --path checkpoints/checkpoint_best.pt \</span><br><span class="line">    --batch-size 128 --beam 5 --remove-bpe</span><br><span class="line"></span><br></pre></td></tr></table></figure><br>找到该文件夹下的.vscode文件，打开其中的launch.json。<br><img src="/img/vscode_remote_debug_md/3.jpg" alt="找到该文件"><br>在vscode中的launch.json文件中添加args参数，具体如下图所示。<br><img src="/img/vscode_remote_debug_md/4.jpg" alt="命令行参数格式"><br><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="comment">// 使用 IntelliSense 了解相关属性。 </span></span><br><span class="line">    <span class="comment">// 悬停以查看现有属性的描述。</span></span><br><span class="line">    <span class="comment">// 欲了解更多信息，请访问: https://go.microsoft.com/fwlink/?linkid=830387</span></span><br><span class="line">    <span class="attr">&quot;version&quot;</span><span class="punctuation">:</span> <span class="string">&quot;0.2.0&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;configurations&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">        <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Python: Current File&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;python&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;request&quot;</span><span class="punctuation">:</span> <span class="string">&quot;launch&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;program&quot;</span><span class="punctuation">:</span> <span class="string">&quot;$&#123;file&#125;&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;console&quot;</span><span class="punctuation">:</span> <span class="string">&quot;integratedTerminal&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;justMyCode&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;args&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="string">&quot;data-bin/iwslt14.tokenized.de-en&quot;</span><span class="punctuation">,</span><span class="string">&quot;--path&quot;</span><span class="punctuation">,</span><span class="string">&quot;checkpoints/checkpoint_best.pt&quot;</span><span class="punctuation">,</span><span class="string">&quot;--batch-size&quot;</span><span class="punctuation">,</span><span class="string">&quot;10&quot;</span><span class="punctuation">,</span><span class="string">&quot;--beam&quot;</span><span class="punctuation">,</span><span class="string">&quot;5&quot;</span><span class="punctuation">,</span><span class="string">&quot;--remove-bpe&quot;</span><span class="punctuation">]</span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure></p><p><strong>相较于命令行参数没有了fairseq-generate，转而到generate.py文件下调试。</strong></p><h2 id="选择环境"><a href="#选择环境" class="headerlink" title="选择环境"></a>选择环境</h2><p>由于python项目可能要在相应的anaconda环境中才能运行，因此需要先选择环境，在vscode中按住<code>ctrl+shift+P</code>调出这个控制界面。<br><img src="/img/vscode_remote_debug_md/5.jpg" alt="选择解释器"><br><img src="/img/vscode_remote_debug_md/6.jpg" alt="选择py3_7环境（之前已经创建好）"></p><h2 id="开始调试"><a href="#开始调试" class="headerlink" title="开始调试"></a>开始调试</h2><p><strong>在generate.py文件下调试。</strong>，设置好断点，在菜单选择<strong>运行-&gt;调试</strong>。<br><img src="/img/vscode_remote_debug_md/7.jpg" alt="就可以看到变量等情况"></p>]]></content>
      
      
      
        <tags>
            
            <tag> vscode </tag>
            
            <tag> 小助手 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>fairseq的使用入门</title>
      <link href="/2022/08/29/fairseq/"/>
      <url>/2022/08/29/fairseq/</url>
      
        <content type="html"><![CDATA[<h2 id="fairseq常用命令"><a href="#fairseq常用命令" class="headerlink" title="fairseq常用命令"></a>fairseq常用命令</h2><h3 id="通用命名参数"><a href="#通用命名参数" class="headerlink" title="通用命名参数"></a>通用命名参数</h3><div class="table-container"><table><thead><tr><th style="text-align:left">命令</th><th style="text-align:left">参数</th><th style="text-align:left">用法</th><th style="text-align:left">可选项/备注</th></tr></thead><tbody><tr><td style="text-align:left">通用命名参数</td><td style="text-align:left"><code>--no-progress-bar</code></td><td style="text-align:left">关闭进度条</td><td style="text-align:left">默认：False</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--log-interval</code></td><td style="text-align:left">每N批记录进度(禁用进度条时)</td><td style="text-align:left">默认：100</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--log-format</code></td><td style="text-align:left">选择日志格式</td><td style="text-align:left">选项：json,none,simple,tqdm</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--log-file</code></td><td style="text-align:left">指定输出metric的日志文件</td><td style="text-align:left"></td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--tensorboard-logdir</code></td><td style="text-align:left">tensorboard的日志文件位置</td><td style="text-align:left">须和-–logdir of running tensorboard相同，默认无日志</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--wandb-project</code></td><td style="text-align:left">用于日志的权重和偏置项目名</td><td style="text-align:left"></td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--seed</code></td><td style="text-align:left">设置随机数种子</td><td style="text-align:left">默认为1</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--cpu</code></td><td style="text-align:left">使用CPU而不是CUDA</td><td style="text-align:left">默认：False</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--tpu</code></td><td style="text-align:left">使用TPU而不是CUDA</td><td style="text-align:left">默认：False</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--bf16</code></td><td style="text-align:left">使用数据格式bfloat16,前提—tpu</td><td style="text-align:left">默认：False</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--memory-efficient-bf16</code></td><td style="text-align:left">使用内存高效的bfloat16,前提—bf16</td><td style="text-align:left">默认：False</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--fp16</code></td><td style="text-align:left">使用数据格式FP16</td><td style="text-align:left">默认：False</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--memory-efficient-fp16</code></td><td style="text-align:left">使用数据格式内存高效的FP16,</td><td style="text-align:left">默认：False</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--fp16-no-flatten-grads</code></td><td style="text-align:left">不展开FP16梯度tensor</td><td style="text-align:left">默认：False</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--fp16-init-scale</code></td><td style="text-align:left"></td><td style="text-align:left">默认：False</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--on-cpu-convert-precision</code></td><td style="text-align:left">浮点数转化为fp16/bf16将在CPU上完成.</td><td style="text-align:left">默认：False</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--amp</code></td><td style="text-align:left">使用自动混合精度</td><td style="text-align:left">默认：False</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--usr-dir</code></td><td style="text-align:left">包含个性扩展的模块路径（tasks/architectures）</td><td style="text-align:left"></td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--empty-cache-freq</code></td><td style="text-align:left">pytorch CUDA缓存清理频率</td><td style="text-align:left">默认：0（不清理）</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--model-parallel-size</code></td><td style="text-align:left">使用并行的GPU数量</td><td style="text-align:left">默认：1</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--quantization-config-path</code></td><td style="text-align:left">quantization配置文件路径</td><td style="text-align:left"></td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--criterion</code></td><td style="text-align:left">损失函数</td><td style="text-align:left">默认：交叉熵</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--tokenizer</code></td><td style="text-align:left">分词工具</td><td style="text-align:left">可选：mosses,nltk,space</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--bpe</code></td><td style="text-align:left">bpe分词</td><td style="text-align:left">可选：byte_bpe, bytes, characters, fastbpe, gpt2, bert, hf_byte_bpe, sentencepiece, subword_nmt</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--optimizer</code></td><td style="text-align:left">优化器</td><td style="text-align:left">可选：adadelta, adafactor, adagrad, adam, adamax, composite, cpu_adam, lamb, nag, sgd</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--lr-scheduler</code></td><td style="text-align:left">学习率管理</td><td style="text-align:left">可选：cosine, fixed, inverse_sqrt, manual, pass_through, polynomial_decay, reduce_lr_on_plateau, step, tri_stage, triangular，默认：fixed</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--scoring</code></td><td style="text-align:left">评价指标</td><td style="text-align:left">可选：bert_score, sacrebleu, bleu, chrf, meteor, wer，默认：bleu</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--task</code></td><td style="text-align:left">任务选项</td><td style="text-align:left">可选：multilingual_language_modeling, speech_unit_modeling, hubert_pretraining, translation等，默认：translation</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--dataset-impl</code></td><td style="text-align:left">处理数据集方式</td><td style="text-align:left">可选：raw, lazy, cached, mmap, fasta, huffman，默认：mmap</td></tr></tbody></table></div><p>命名参数省略：</p><ul><li>aim-repo</li><li>aim-run-hash</li><li>azureml-logging</li><li>fp16-init-scale</li><li>fp16-scale-window</li><li>fp16-scale-tolerance</li><li>min-loss-scale</li><li>threshold-loss-scale</li><li>amp-batch-retries</li><li>amp-init-scale</li><li>amp-scale-window</li><li>all-gather-list-size</li><li>profile</li><li>reset-logging</li><li>suppress-crashes</li><li>use-plasma-view</li><li>plasma-path</li></ul><h3 id="fairseq-preprocess参数"><a href="#fairseq-preprocess参数" class="headerlink" title="fairseq-preprocess参数"></a>fairseq-preprocess参数</h3><div class="table-container"><table><thead><tr><th style="text-align:left">命令</th><th style="text-align:left">参数</th><th style="text-align:left">用法</th><th style="text-align:left">可选项/备注</th></tr></thead><tbody><tr><td style="text-align:left">fairseq-preprocess</td><td style="text-align:left"></td><td style="text-align:left">数据预处理：建词典并将训练数据二进制化</td><td style="text-align:left">以下为预处理命令</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>-s, --source-lang</code></td><td style="text-align:left">源语言</td><td style="text-align:left"></td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>-t, --target-lang</code></td><td style="text-align:left">目标语言</td><td style="text-align:left"></td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--trainpref</code></td><td style="text-align:left">两个语言的训练文件前缀</td><td style="text-align:left"></td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--validpref</code></td><td style="text-align:left">两个语言的验证文件前缀</td><td style="text-align:left"></td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--testpref</code></td><td style="text-align:left">两个语言的测试文件前缀</td><td style="text-align:left">说明：例如我们的数据中只有训练数据和测试数据，且文件后缀为src和tgt，即train.src、train.tgt、test.src和test.tgt，那么通过指定—source-lang src —target-lang tgt —trainpref train —testpref test，也可以读取的对应的文件。</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--align-suffix</code></td><td style="text-align:left">对齐后缀</td><td style="text-align:left">未知</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--destdir</code></td><td style="text-align:left">输出文件位置</td><td style="text-align:left">默认：data-bin</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--thresholdtgt</code></td><td style="text-align:left">将目标语言出现次数少于阈值的词映射到unkown</td><td style="text-align:left">默认：0</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--thresholdsrc</code></td><td style="text-align:left">将源语言出现次数少于阈值的词映射到unkown</td><td style="text-align:left">默认：0</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--tgtdict</code></td><td style="text-align:left">重复使用给定的目标语言字典</td><td style="text-align:left"></td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--srcdict</code></td><td style="text-align:left">重复使用给定的源语言字典</td><td style="text-align:left"></td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--nwordstgt</code></td><td style="text-align:left">目标语言中需要retain的词数量，(解决oov问题）</td><td style="text-align:left">默认：-1</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--nwordssrc</code></td><td style="text-align:left">源语言中需要retain的词数量</td><td style="text-align:left">默认：-1</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--alignfile</code></td><td style="text-align:left">对齐文件（可选）</td><td style="text-align:left">翻译 文字一一对齐</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--joined-dictionary</code></td><td style="text-align:left">生成联合的字典</td><td style="text-align:left">默认：False</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--only-source</code></td><td style="text-align:left">只处理源语言</td><td style="text-align:left">默认：False</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--padding-factor</code></td><td style="text-align:left">填充字典数量为N的倍数</td><td style="text-align:left">默认：8</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--workers</code></td><td style="text-align:left">并行进程数量</td><td style="text-align:left">默认：1</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--dict-only</code></td><td style="text-align:left">只构建字典</td><td style="text-align:left">默认：False</td></tr></tbody></table></div><h3 id="fairseq-train参数"><a href="#fairseq-train参数" class="headerlink" title="fairseq-train参数"></a>fairseq-train参数</h3><div class="table-container"><table><thead><tr><th style="text-align:left">命令</th><th style="text-align:left">参数</th><th style="text-align:left">用法</th><th style="text-align:left">可选项/备注</th></tr></thead><tbody><tr><td style="text-align:left">fairseq-train</td><td style="text-align:left"></td><td style="text-align:left">在一个或多个GPU上训练模型</td><td style="text-align:left">以下为训练命令</td></tr><tr><td style="text-align:left">数据集加载</td><td style="text-align:left"><code>--num-workers</code></td><td style="text-align:left">加载数据的并行进程数量</td><td style="text-align:left">默认：1</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--skip-invalid-size-inputs-valid-test</code></td><td style="text-align:left">忽略验证集和测试集中太长或太短的句子</td><td style="text-align:left">默认：False</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--max-token</code></td><td style="text-align:left">一个batch中tokens的最大数量</td><td style="text-align:left"></td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--batch-size,--max-sentences</code></td><td style="text-align:left">batch size</td><td style="text-align:left"></td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--required-batch-size-multiple</code></td><td style="text-align:left">要求batchsize是该值的倍数</td><td style="text-align:left">默认：8</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--required-seq-len-multiple</code></td><td style="text-align:left">要求最大序列长度是该值的倍数</td><td style="text-align:left">默认：1</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--data-buffer-size</code></td><td style="text-align:left">预先加载的batch数量</td><td style="text-align:left">default：10</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--train-subset</code></td><td style="text-align:left">数据集中用于训练的子集</td><td style="text-align:left">例如：trian,valid,test。默认：train</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--valid-subset</code></td><td style="text-align:left">数据集中用于验证的子集</td><td style="text-align:left">例如：trian,valid,test。默认：valid</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--ignore-unused-valid-subsets</code></td><td style="text-align:left">do not raise error if valid subsets are ignored</td><td style="text-align:left">默认：False（未知）</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--validate-interval</code></td><td style="text-align:left">每N个epochs在验证集上验证</td><td style="text-align:left">默认：1</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--validate-interval-updates</code></td><td style="text-align:left">每N个updates在验证集上验证</td><td style="text-align:left">默认：0</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--validate-after-updates</code></td><td style="text-align:left">在N次更新后才验证</td><td style="text-align:left">默认：0</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--fixed-validation-seed</code></td><td style="text-align:left">设置验证时的种子值</td><td style="text-align:left"></td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--disable-validation</code></td><td style="text-align:left">取消验证</td><td style="text-align:left">default:False</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--max-tokens-valid</code></td><td style="text-align:left">验证时每批次的最大tokens数</td><td style="text-align:left">默认和 <code>--max-tokens</code>相同</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--batch-size-valid</code></td><td style="text-align:left">验证时batchsize</td><td style="text-align:left">默认和<code>--batch-size</code>相同</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--max-valid-steps，--nval</code></td><td style="text-align:left">评估的总batch数量</td><td style="text-align:left"></td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--curriculum</code></td><td style="text-align:left">在前N个epochs中不打乱batch</td><td style="text-align:left">N默认：0</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--gen-subset</code></td><td style="text-align:left">选择生成的数据集子集（train,valid,text）</td><td style="text-align:left">默认：test</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--num-shards</code></td><td style="text-align:left">N文件切片</td><td style="text-align:left">默认：1</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--shard-id</code></td><td style="text-align:left">生成shards的其中第i个（i&lt;num-shards）</td><td style="text-align:left">默认：0</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--grouped-shuffling</code></td><td style="text-align:left">在num_shards组中打乱批次，使得每个子进程中的序列长度相似，前提batches按照长度排序</td><td style="text-align:left">默认：False</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--update-epoch-batch-itr</code></td><td style="text-align:left"></td><td style="text-align:left">默认：False （未知）</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--update-ordered-indices-seed</code></td><td style="text-align:left"></td><td style="text-align:left">默认：False （未知）</td></tr><tr><td style="text-align:left">分布式训练</td><td style="text-align:left"><code>--distributed-world-size</code></td><td style="text-align:left">设置所有节点的GPU总数，等于可见GPU数量</td><td style="text-align:left">默认：1</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--distributed-num-procs</code></td><td style="text-align:left">fork的子进程数量，等于可见GPU数量</td><td style="text-align:left">默认：1</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--distributed-rank</code></td><td style="text-align:left">目前进程的级别</td><td style="text-align:left">默认：0 (未知)</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--distributed-backend</code></td><td style="text-align:left">分布式后端</td><td style="text-align:left">默认：nccl (未知)</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--distributed-init-method</code></td><td style="text-align:left">初始化方法</td><td style="text-align:left">(未知)</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--distributed-port</code></td><td style="text-align:left">端口号，如果设置了上一条就不用管</td><td style="text-align:left">默认：-1(未知)</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--device-id,--local-rank</code></td><td style="text-align:left">使用哪一个GPU</td><td style="text-align:left">默认：0(未知)</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--distributed-no-spawn</code></td><td style="text-align:left">即使有多个GPU也不生成多个进程</td><td style="text-align:left">默认：False(未知)</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--ddp-backend</code></td><td style="text-align:left">DistributedDataParallel后端</td><td style="text-align:left">默认：pytorch_ddp</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--fix-batches-to-gpus</code></td><td style="text-align:left">不要在gpu之间切换批次;这减少了整体的随机性，可能会影响精度，但避免了重新读取数据的成本</td><td style="text-align:left">默认：False</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--find-unused-parameters</code></td><td style="text-align:left">控制未使用参数检测</td><td style="text-align:left">默认：False （未知）</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--gradient-as-bucket-view</code></td><td style="text-align:left"></td><td style="text-align:left">默认：False （未知）</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--heartbeat-timeout</code></td><td style="text-align:left">如果N秒内进程没反应就Kill，N为-1的话不kill</td><td style="text-align:left">默认：-1</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--broadcast-buffers</code></td><td style="text-align:left">在GPU之间复制不可训练的参数</td><td style="text-align:left">默认：False</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--slowmo-momentum</code></td><td style="text-align:left">slowMo动量设置</td><td style="text-align:left"></td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--slowmo-base-algorithm</code></td><td style="text-align:left">基础算法sgd或localsgd</td><td style="text-align:left">默认:localsgd</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--localsgd-frequency</code></td><td style="text-align:left">localsgd的allreduce频率</td><td style="text-align:left">默认:3</td></tr><tr><td style="text-align:left">部分其他参数见文档</td><td style="text-align:left"></td><td style="text-align:left"></td><td style="text-align:left"></td></tr><tr><td style="text-align:left">模型配置</td><td style="text-align:left"><code>--arch -a</code></td><td style="text-align:left">模型架构选择</td><td style="text-align:left">可选项项:transformer_tiny,transformer,transformer_iwslt_de_en, transformer_wmt_en_de,roberta_base…</td></tr><tr><td style="text-align:left">优化设置</td><td style="text-align:left"><code>--max-epoch</code></td><td style="text-align:left">到特定的epoch时停止训练</td><td style="text-align:left">默认：0</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--max-upadte</code></td><td style="text-align:left">到特定的update时停止训练</td><td style="text-align:left">默认：0</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--stop-time-hours</code></td><td style="text-align:left">到指定的小时数后停止训练</td><td style="text-align:left">默认：0</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--clip-norm</code></td><td style="text-align:left">梯度剪切</td><td style="text-align:left">默认：0</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--sentence-avg</code></td><td style="text-align:left">使用一批次的句子数量正则化梯度（而不是tokens数量）</td><td style="text-align:left">默认：False</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--update-freq</code></td><td style="text-align:left">在第i个epoch时按照每Ni个批次更新参数</td><td style="text-align:left">默认：1</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--lr</code></td><td style="text-align:left">在前N个epoch设置学习率，使用LR_N的话epochs&gt;N</td><td style="text-align:left">默认：0.25 （未知）</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--stop-min-lr</code></td><td style="text-align:left">当学习率降到该值时停止训练，默认不停止</td><td style="text-align:left">默认：-1.0</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--use-bmuf</code></td><td style="text-align:left">使用全局优化器来同步多GPU/shards上的模型</td><td style="text-align:left">默认：False</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--skip-remainder-batch</code></td><td style="text-align:left">如果设置这个选项，则会跳过最后一批不满的批次</td><td style="text-align:left">默认：False</td></tr><tr><td style="text-align:left">检查点</td><td style="text-align:left"><code>--save-dir</code></td><td style="text-align:left">保存检查点的路径</td><td style="text-align:left">默认：checkpoints</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--restore-file</code></td><td style="text-align:left">加载已保存检查点文件的路径</td><td style="text-align:left">默认：checkpoints</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--continue-once</code></td><td style="text-align:left">从该检查点继续，除非设置了<code>--restore-file</code></td><td style="text-align:left"></td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--finetune-from-model</code></td><td style="text-align:left">从预训练模型微调</td><td style="text-align:left">未知</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--reset-dataloader</code></td><td style="text-align:left">如果设置了，就不从checkpoints中加载dataloader state</td><td style="text-align:left">默认：False (未知)</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--reset-lr-sheduler</code></td><td style="text-align:left">如果设置了，就不从checkpoints中加载lr sheduler state</td><td style="text-align:left">默认：False (未知)</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--reset-meters</code></td><td style="text-align:left">如果设置了，就不从checkpoints中加载meters</td><td style="text-align:left">默认：False (未知)</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--reset-optimizer</code></td><td style="text-align:left">如果设置了，就不从checkpoints中加载optimizer state</td><td style="text-align:left">默认：False (未知)</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--save-interval</code></td><td style="text-align:left">每N个epoch保存checkpoint</td><td style="text-align:left">默认：1</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--save-interval-updates</code></td><td style="text-align:left">每N个epoch验证并保存checkpoint</td><td style="text-align:left">默认：0</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--keep-interval-updates</code></td><td style="text-align:left">保存上一个选项的最后N个checkpoints</td><td style="text-align:left">默认：-1</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--keep-interval-updates-pattern</code></td><td style="text-align:left">和上一条同时使用，不删除第k个checkpoints，其中k%keep_interval_updates_pattern==0</td><td style="text-align:left">默认：-1</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--keep-last-epochs</code></td><td style="text-align:left">保存最后N个epoch的checkpoints</td><td style="text-align:left">默认：-1</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--keep-best-epochs</code></td><td style="text-align:left">保存N个最佳sorce的checkpoints</td><td style="text-align:left">默认：-1</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--no-save</code></td><td style="text-align:left">不保存model和checkpoints</td><td style="text-align:left">默认：False</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--no-epoch-checkpoints</code></td><td style="text-align:left">只保存最后一个epoch和最佳的checkpoints</td><td style="text-align:left">默认：False</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--no-last-checkpoints</code></td><td style="text-align:left">不保存最后一个epoch checkpoints</td><td style="text-align:left">默认：False</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--no-save-optimizer-state</code></td><td style="text-align:left">不将optimizer state视为checkpoint的一部分</td><td style="text-align:left">默认：False</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--best-checkpoint-metric</code></td><td style="text-align:left">best checkpoint的标准</td><td style="text-align:left">默认：loss （<code>重要</code>）</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--maximize-best-checkpoint-metric</code></td><td style="text-align:left">选择最大的metric value来保存最佳的checkpoints</td><td style="text-align:left">默认：False（未知）</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--patience</code></td><td style="text-align:left">连续的N次验证性能没有提升则停止训练，会被<code>–validate-interval</code>影响</td><td style="text-align:left">默认：-1</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--checkpoint-suffix</code></td><td style="text-align:left">检查点文件的后缀</td><td style="text-align:left">默认：空</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--checkpoint-shard-count</code></td><td style="text-align:left">如果checkpoints文件超过300GB,会将其切片防止存储不足。</td><td style="text-align:left">默认：1</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--load-checkpoint-on-all-dp-ranks</code></td><td style="text-align:left">在所有并行设备上加载checkpoints，从第一个</td><td style="text-align:left">默认：False</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--write-checkpoints-asynchronously, --save-async</code></td><td style="text-align:left">异步保存检查点，功能测试中</td><td style="text-align:left">默认：False</td></tr></tbody></table></div><h3 id="fairseq-generate参数"><a href="#fairseq-generate参数" class="headerlink" title="fairseq-generate参数"></a>fairseq-generate参数</h3><div class="table-container"><table><thead><tr><th style="text-align:left">命令</th><th style="text-align:left">参数</th><th style="text-align:left">用法</th><th style="text-align:left">可选项/备注</th></tr></thead><tbody><tr><td style="text-align:left">fairseq-generate</td><td style="text-align:left">使用已训练的模型翻译预先处理好的数据</td><td style="text-align:left"></td><td style="text-align:left"></td></tr><tr><td style="text-align:left">Generation</td><td style="text-align:left"><code>--path</code></td><td style="text-align:left">模型文件路径，冒号间隔</td><td style="text-align:left"></td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--post-process，--remove-bpe</code></td><td style="text-align:left">去除BPE、字母分割等</td><td style="text-align:left"></td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--quiet</code></td><td style="text-align:left">只输出最后的分数</td><td style="text-align:left">默认：False</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--model-overrides</code></td><td style="text-align:left">在生成时重载模型参数，替换训练时的参数</td><td style="text-align:left">默认：无</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--results-path</code></td><td style="text-align:left">保存评价结果的路径</td><td style="text-align:left"></td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--beam</code></td><td style="text-align:left">beam size</td><td style="text-align:left">默认：5</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--nbest</code></td><td style="text-align:left">输出翻译的结果数</td><td style="text-align:left">默认：1</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--max-len-a</code></td><td style="text-align:left">生成句子最大长度ax+b,x是源句子长度</td><td style="text-align:left">同下使用，默认：0</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--max-len-b</code></td><td style="text-align:left">生成句子最大长度ax+b,x是源句子长度</td><td style="text-align:left">同上使用，默认：200</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--min-len</code></td><td style="text-align:left">最小的生成长度</td><td style="text-align:left">默认：1</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--match-source-len</code></td><td style="text-align:left">生成的句子长度和原句子长度相同</td><td style="text-align:left">默认：False</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--unnormalized</code></td><td style="text-align:left">compare unnormalized hypothesis scores</td><td style="text-align:left">默认：False（未知）</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--no-beamable-mm</code></td><td style="text-align:left">在attention layers中不使用BeamableMM</td><td style="text-align:left">默认：False</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--lenpen</code></td><td style="text-align:left">长度惩罚，如果小于1.0倾向短句子，大于1.0则倾向长句子</td><td style="text-align:left">默认：1</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--unkpen</code></td><td style="text-align:left">未知单词惩罚，如果小于0产生更多unks，大于0产生更少</td><td style="text-align:left">默认：0</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--replace-unk</code></td><td style="text-align:left">替换unk，使用字典</td><td style="text-align:left"></td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--sacrebleu</code></td><td style="text-align:left">使用sacrebleu</td><td style="text-align:left">默认：False</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--score-reference</code></td><td style="text-align:left">只给参考翻译打分</td><td style="text-align:left">默认：False</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--prefix-size</code></td><td style="text-align:left">给定前缀长度来初始化生成</td><td style="text-align:left">默认：0（未知）</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--no-repeat-ngram-size</code></td><td style="text-align:left">ngram中不能重复生成</td><td style="text-align:left">默认：0（未知）</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--sampling</code></td><td style="text-align:left">在假设中采样而不是使用beam search</td><td style="text-align:left">默认：False</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--sampling-topk</code></td><td style="text-align:left">从K个可能的下个字中采样而不是从全部词中采样</td><td style="text-align:left">默认：-1</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--constraints</code></td><td style="text-align:left">词法约束解码过程</td><td style="text-align:left">可选：ordered,unordered（未知）</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--temperature</code></td><td style="text-align:left">temperature for generation</td><td style="text-align:left">默认：1.0 （未知）</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--diverse-beam-groups</code></td><td style="text-align:left">组数</td><td style="text-align:left">默认：-1（未知）</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--diverse-beam-strength</code></td><td style="text-align:left">strength of diversity penalty for Diverse Beam Search</td><td style="text-align:left">默认：-1（未知）</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--diverse-rate</code></td><td style="text-align:left">strength of diversity penalty for Diverse Siblings Search</td><td style="text-align:left">默认：-1（未知）</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--print-step</code></td><td style="text-align:left">输出steps</td><td style="text-align:left">默认：False</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--decoding-format</code></td><td style="text-align:left">解码格式</td><td style="text-align:left">可选：unigram, ensemble, vote, dp, bs</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--no-seed-provided</code></td><td style="text-align:left">设置了，生成时就不初始化种子</td><td style="text-align:left">默认：False</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"><code>--eos-token</code></td><td style="text-align:left">设置停止的token</td></tr></tbody></table></div><p>generation省略：</p><ul><li>print-alignment</li><li>lm-path</li><li>lm-weight</li><li>iter-decode-eos-penalty</li><li>iter-decode-max-iter</li><li>iter-decode-force-max-iter</li><li>iter-decode-with-beam</li><li>iter-decode-with-external-reranker</li></ul><h2 id="fairseq可扩展部分"><a href="#fairseq可扩展部分" class="headerlink" title="fairseq可扩展部分"></a>fairseq可扩展部分</h2><h3 id="Tasks"><a href="#Tasks" class="headerlink" title="Tasks"></a>Tasks</h3><p>Tasks存储字典，并且对加载/迭代数据集提供帮助，初始化Model/Criterion，计算损失。用法示例如下：<br><img src="/img/fairseq_md/1.jpg" alt="用例"></p><div class="table-container"><table><thead><tr><th style="text-align:left">命令</th><th style="text-align:left">参数</th><th style="text-align:left">用法</th><th style="text-align:left">可选项/备注</th></tr></thead><tbody><tr><td style="text-align:left">Additional command-line arguments</td><td style="text-align:left"></td><td style="text-align:left"></td><td style="text-align:left">待续未完</td></tr></tbody></table></div><h3 id="Models"><a href="#Models" class="headerlink" title="Models"></a>Models</h3><p>该部分定义网络前馈过程，封装可学习参数，可以设置模型架构<br><img src="/img/fairseq_md/3.jpg" alt="Additional command-line arguments"></p><h3 id="Criterions"><a href="#Criterions" class="headerlink" title="Criterions"></a>Criterions</h3><p>给定model和batch，计算损失函数</p><h3 id="Optimizers"><a href="#Optimizers" class="headerlink" title="Optimizers"></a>Optimizers</h3><p>根据梯度更新模型参数</p><h3 id="学习率管理"><a href="#学习率管理" class="headerlink" title="学习率管理"></a>学习率管理</h3><h3 id="数据加载和处理"><a href="#数据加载和处理" class="headerlink" title="数据加载和处理"></a>数据加载和处理</h3><h3 id="模型模块"><a href="#模型模块" class="headerlink" title="模型模块"></a>模型模块</h3><h2 id="fairseq-translation使用"><a href="#fairseq-translation使用" class="headerlink" title="fairseq-translation使用"></a>fairseq-translation使用</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Download and prepare the data</span></span><br><span class="line"><span class="built_in">cd</span> examples/translation/</span><br><span class="line">bash prepare-iwslt14.sh</span><br><span class="line"><span class="built_in">cd</span> ../..</span><br><span class="line"></span><br><span class="line"><span class="comment"># Preprocess/binarize the data</span></span><br><span class="line">TEXT=examples/translation/iwslt14.tokenized.de-en</span><br><span class="line">fairseq-preprocess --source-lang de --target-lang en \</span><br><span class="line">    --trainpref <span class="variable">$TEXT</span>/train --validpref <span class="variable">$TEXT</span>/valid --testpref <span class="variable">$TEXT</span>/test \</span><br><span class="line">    --destdir data-bin/iwslt14.tokenized.de-en \</span><br><span class="line">    --workers 20</span><br></pre></td></tr></table></figure><p><img src="/img/fairseq_md/5.jpg" alt="命令行截图"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=0 fairseq-train \</span><br><span class="line">    data-bin/iwslt14.tokenized.de-en \</span><br><span class="line">    --<span class="built_in">arch</span> transformer_iwslt_de_en --share-decoder-input-output-embed \</span><br><span class="line">    --optimizer adam --adam-betas <span class="string">&#x27;(0.9, 0.98)&#x27;</span> --clip-norm 0.0 \</span><br><span class="line">    --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 \</span><br><span class="line">    --dropout 0.3 --weight-decay 0.0001 \</span><br><span class="line">    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \</span><br><span class="line">    --max-tokens 4096 \</span><br><span class="line">    --eval-bleu \</span><br><span class="line">    --eval-bleu-args <span class="string">&#x27;&#123;&quot;beam&quot;: 5, &quot;max_len_a&quot;: 1.2, &quot;max_len_b&quot;: 10&#125;&#x27;</span> \</span><br><span class="line">    --eval-bleu-detok moses \</span><br><span class="line">    --eval-bleu-remove-bpe \</span><br><span class="line">    --eval-bleu-print-samples \</span><br><span class="line">    --best-checkpoint-metric bleu --maximize-best-checkpoint-metric</span><br></pre></td></tr></table></figure><p><img src="/img/fairseq_md/6.jpg" alt="训练截图"><br><img src="/img/fairseq_md/7.jpg" alt="训练159个epoch截图"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">fairseq-generate data-bin/iwslt14.tokenized.de-en \</span><br><span class="line">    --path checkpoints/checkpoint_best.pt \</span><br><span class="line">    --batch-size 128 --beam 5 --remove-bpe</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><img src="/img/fairseq_md/8.jpg" alt="在测试集上验证截图"></p>]]></content>
      
      
      
        <tags>
            
            <tag> fairseq </tag>
            
            <tag> 机器翻译 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
